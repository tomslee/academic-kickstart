---
title: "Algorithmic fairness at equilibrium"
author: ["Tom Slee"]
date: 2018-11-23
publishDate: 2018-11-23
draft: true
url_pdf: pdf/2018-ai_equilibrium.pdf
summary: Work in progress on elasticity.
---
Introduction
============

We are in the middle of an explosion of concern about bias and
unfairness in algorithms that make decisions about people. Companies use
algorithms to sort, rank, score, filter, and classify people for many
purposes: advertising, social services, hiring, imprisoning, and much
more.

Much of the analysis so far has been static (and statistical). That is,
it treats the algorithm as a camera, recording and portraying some
aspect of the external world and asks: does it portray this aspect of
the world fairly and faithfully? But systems for sorting do not just
portray the world, they change it. People care about being classified,
and change their behavior accordingly. When previously-innocuous data
about people is used as input to decisions of consequence, those who
record the data change what they record. When decision-making systems
generate results that its owners and operators have problems with, the
gap between intent and algorithm becomes the subject of dispute.

While these aspects of what is sometimes called algorithmic governance
have certainly been recognized, they have so far been underplayed. This
essay is an attempt to capture some of the consequences of algorithmic
decision-making beyond the static analysis.

Exit, voice, and scale
======================

Why automated systems matter.

A common response to complaints about algorithmic bias and opacity has
been to observe that people too are biased, and that people's
decision-making is opaque, sometimes even to ourselves. A job
application rejected by a human is not usually subject to appeal: why
would we hold a machine to higher standards?

We are increasingly moving to a world of automated decision making based
on quantifiable metrics. From individuals to organizations and formal
policies to computerized systems and internet platforms. It's the change
in power of the decision-maker that matters most. We can learn a lot
from other classification and ranking systems. Also, fauxtomation.

Deep Learning has introduced a new dimension. Even supposedly
unstructured problems (image recognition) can be solved by computerized
means. Intuition can now be reproduced at scale. It doesn't always work
\-- there are plenty of crap, badly-thought-out deep learning systems
out there -- but the best are amazing. Conversation is now at scale:
Siri, Alexa, and Google Home now have millions of distinct personal
conversations per day.

Formal organizational policies and standards provide systematic
decisions that may not be encoded in algorithmic form. As just one
example, health and safety inspections of restaurants follow a very
specific format and process, and the role of human inspectors is
constrained by the demands of that system, which limits human
flexibility and initiative. Why the problem with machine decisions when
systematic decisions already surround us?

Individual decision-making that reflects a culture can be problematic.
Racism and the idea of fit. In the tech world, VC funding of
entrepreneurs is left very much to the gut reactions of individuals, and
many would say it reflects biases suffused with gender expectations
about risk-taking behavior, acceptable limits, and so on.

Also: not all computerized rating systems are important. Reputational
systems like Klout overreached. After an initial flurry, and worries
about the consequences of social rating, nobody paid attention: your
rating did not matter. Klout folded. But China's social credit system is
different.

What makes the difference here is scale. Computerized systems have the
potential to operate at massive scale.

Engines of anxiety: trapped in the web
--------------------------------------

Rating systems can be difficult to exit. They become powerful.

Law School ratings as an example of a non-computational rating system
that exerts power.

Yelp: no exit
-------------

Yelp is an example: restaurants cannot exit, and yet their score
matters. So voice is the only alternative. Yelp's treatment at the hands
of Google provides an ironic postscript.

Conclusion: algorithmic decision-making systems are going to be
important. Voice matters, and people will respond to them in different
ways to how we respond to individual People matter too, but let's not
kid ourselves the same is present.

The static case offers hope: if we can identify and account for bias, if
we can take diverse inputs, if we can make our systems transparent,
maybe we can improve on individual human decision-making. The critique
is constructive, and many companies have now embraced it. But there are
other problems too....

Trying to exit by faking low scores.

Deep Learning systems: pervasive systems
----------------------------------------

Topologies of decisions: sequential stacks, and multi-use public
information.

Systems as powerful agents
==========================

Any classification system changes the incentives.

Sorting things out and causes of death in the Netherlands. Engines and
cameras. Financial systems, networks. Performativity.

Scoring and ranking: pooling and separating outcomes.

Seeing like a state
-------------------

Optimizing for one outcome assuming no change.

Accuracy is not enough: systems change power
--------------------------------------------

Self-driving vehicle comparisons.

Airbnb and portrayals of its data.

Harcourt and carrying drugs
---------------------------

Accuracy against static data is not enough. We need to go beyond static
analysis to get the full story.

Optimized systems may not create the best results.

From decision-maker to data-collector: preparing inputs
=======================================================

Workers who prepare official reports. Humans in the loop.

Ontario Welfare workers
-----------------------

Changed behavior. De-skilling.

Algorithmic Inequality: avoiding labels.

Deep Learning and Healthcare
----------------------------

Changes the role of the doctor (de-professionalize) which will lower
quality of input. Opens opportunities for "expert navigating the
system".

Reputation systems and inflation
--------------------------------

Accuracy is not the point.

Divergent responses
===================

Some systems cannot correct for the responses they provoke.

Essay writing
-------------

Large elasticities. Exposes assumptions, but also opens up questions of
gaming. Simon and elegance.

Social media incentives
-----------------------

Driven by the algorithm.

Deep learning and fragility
---------------------------

Andrew Ng.

Platform responses to user action
=================================

Facebook and Airbnb and Yelp: ill-defined values and algorithms.
Facebook: blaming people for following incentives that they create.

Outlawing user actions
----------------------

Keeping the system clean by punishing individual action.

Yelp again

Andrew Ng and autonomous vehicles.

Acceptance
----------

Essay writing as good writing.

The value claim
---------------

Airbnb and hosts.

Fake news.

Whose responsibility
--------------------

The software development process.

Taking ownership of the gap. Work with us to improve. I don't know about
insoluble, but certainly underestimating the scale of the problem
because they did not recognize that they are introducing new incentives.

Deep Learning systems: will they always be vulnerable? What
distinguishes the unexpected from the malicious?

Autonomy and the right to innovate
==================================

Only some people can exit. Innovation and experimentation at the
platform level replaces innovation and experimentation at the level of
the managed.

Who can learn from mistakes?
----------------------------

Systems learn from mistakes: the neural paradigm.

Speech as exploration, not statement of opinion.

Learning from mistakes vs predictive accuracy. The static individual and
the ability to change.

Bibliography
============
